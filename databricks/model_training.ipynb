# Databricks notebook for model training in MedGenAI

# Import necessary libraries
import tensorflow as tf
import numpy as np
import pandas as pd

# Load processed data
processed_data = spark.read.parquet("/data/processed-data")
processed_data = processed_data.toPandas()

# Preprocess data for training
X = processed_data[["chromosome", "position", "reference", "alternate"]].values
y = processed_data["diagnosis"].values

# Split data into training and validation sets
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# Define the generative model
model = tf.keras.Sequential([
  tf.keras.layers.Dense(64, activation='relu', input_shape=(4,)),
  tf.keras.layers.Dense(32, activation='relu'),
  tf.keras.layers.Dense(1, activation='sigmoid')
])

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))

# Evaluate the model
loss, accuracy = model.evaluate(X_val, y_val)
print("Validation loss: {:.4f}".format(loss))
print("Validation accuracy: {:.4f}".format(accuracy))

# Save the trained model
model.save("/model/medgenai-model")

# Load the trained model
loaded_model = tf.keras.models.load_model("/model/medgenai-model")

# Use the trained model for inference
new_data = np.array([[1, 10000, "A", "T"]])
prediction = loaded_model.predict(new_data)
print("Prediction: {:.4f}".format(prediction[0][0]))
